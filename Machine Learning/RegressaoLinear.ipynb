{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f2b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Carregar dados\n",
    "df = pd.read_csv(\"C:/Users/rgs12/Downloads/productivity+prediction+of+garment+employees/garments_worker_productivity.csv\")\n",
    "\n",
    "# informações básicas e primeiras linhas\n",
    "df.info()\n",
    "print(df.head())\n",
    "\n",
    "# Verificar e ver valores ausentes\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_percent = (missing_counts / len(df)) * 100\n",
    "print(\"Valores em falta por coluna:\\n\", missing_counts)\n",
    "print(\"\\nPercentual de valores em falta por coluna:\\n\", missing_percent)\n",
    "\n",
    "# Imputar valores ausentes\n",
    "median_wip_department = df.groupby('department')['wip'].transform('median')\n",
    "df['wip'] = df['wip'].fillna(median_wip_department).fillna(df['wip'].median())\n",
    "\n",
    "# Garantir que não há valores ausentes\n",
    "assert df['wip'].isnull().sum() == 0, \"Ainda existem valores faltantes.\"\n",
    "print(\"\\nImputação concluída. Não há mais valores ausentes.\")\n",
    "\n",
    "#Normalização/Padrão\n",
    "#Selecionamos colunas numéricas (exceto target) para padronização.\n",
    "numeric_cols = df.select_dtypes(include=['float64','int64']).columns.drop('actual_productivity')\n",
    "scaler = StandardScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "# Verificar médias e desvios\n",
    "print(df[numeric_cols].agg(['mean','std']))\n",
    "\n",
    "#Aplicação de Modelos de Aprendizagem Automática\n",
    "#Converter `date` para datetime e extrair `year`, `month`, `day_num`.\n",
    "#Codificar dummies para `quarter`, `department`, `day`.\n",
    "#%%\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=False)\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day_num'] = df['date'].dt.day\n",
    "\n",
    "cat_cols = ['quarter','department','day']\n",
    "df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Preparar dataframe de modelagem (remover colunas irrelevantes)\n",
    "df_model = df.drop(['date'], axis=1)\n",
    "\n",
    "\n",
    "# Divisão Treino/Teste\n",
    "X = df_model.drop('actual_productivity', axis=1)\n",
    "y = df_model['actual_productivity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Treino: {X_train.shape}, Teste: {X_test.shape}\")\n",
    "\n",
    "#Regressão Linear\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "print(f\"Linear Regression -> MSE: {mse_lr:.4f}, R2: {r2_lr:.4f}\")\n",
    "\n",
    "# Scatter plot: previsto vs real\n",
    "plt.figure()\n",
    "plt.scatter(y_test, y_pred_lr, alpha=0.6)\n",
    "plt.xlabel('Productivity Real')\n",
    "plt.ylabel('Productivity Prevista')\n",
    "plt.title('Linear Regression: Real vs Previsto')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.show()\n",
    "\n",
    "#Modelo Avançado: Random Forest + GridSearch\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50,100],\n",
    "    'max_depth': [None,10,20],\n",
    "    'min_samples_split': [2,5]\n",
    "}\n",
    "grid = GridSearchCV(rf, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "best_rf = grid.best_estimator_\n",
    "print(f\"Melhores parâmetros RF: {grid.best_params_}\")\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest -> MSE: {mse_rf:.4f}, R2: {r2_rf:.4f}\")\n",
    "\n",
    "\n",
    "#histogramas e mapa de calor?\n",
    "sns.kdeplot(df['over_time'], fill=True, color='#2ecc71')  \n",
    "plt.title('Densidade de Horas Extras por Funcionário')  \n",
    "plt.xlabel('Horas Extras') \n",
    "\n",
    "for col in numeric_cols:\n",
    "    plt.figure()\n",
    "    plt.hist(df[col], bins=30)\n",
    "    plt.title(f\"Histograma de {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "# Correlação\n",
    "df_corr = df[numeric_cols.tolist() + ['actual_productivity']].corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.matshow(df_corr, fignum=1)\n",
    "plt.title('Mapa de Calor das Correlações', pad=20)\n",
    "plt.xticks(range(len(df_corr.columns)), df_corr.columns, rotation=90)\n",
    "plt.yticks(range(len(df_corr.columns)), df_corr.columns)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Boxplots das variáveis numéricas?\n",
    "for col in numeric_cols:\n",
    "    plt.figure()\n",
    "    plt.boxplot(df[col], vert=False)\n",
    "    plt.title(f\"Boxplot de {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
